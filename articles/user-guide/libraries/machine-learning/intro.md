---
title: Biblioteca de machine learning quântica
description: Saiba como é que a aprendizagem automática é usada em sistemas quânticos
author: alexeib2
ms.author: alexeib
ms.date: 11/22/2019
ms.topic: conceptual
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: e2f4a4a63eef40474856426b3b29652b5d3053b2
ms.sourcegitcommit: 71605ea9cc630e84e7ef29027e1f0ea06299747e
ms.translationtype: MT
ms.contentlocale: pt-PT
ms.lasthandoff: 01/26/2021
ms.locfileid: "98854023"
---
# <a name="introduction-to-quantum-machine-learning"></a><span data-ttu-id="0be26-103">Introdução à Aprendizagem de Máquinas Quânticas</span><span class="sxs-lookup"><span data-stu-id="0be26-103">Introduction to Quantum Machine Learning</span></span>

## <a name="framework-and-goals"></a><span data-ttu-id="0be26-104">Enquadramento e metas</span><span class="sxs-lookup"><span data-stu-id="0be26-104">Framework and goals</span></span>

<span data-ttu-id="0be26-105">A codificação quântica e o processamento da informação é uma poderosa alternativa aos classificadores quânticos de aprendizagem de máquinas clássicas.</span><span class="sxs-lookup"><span data-stu-id="0be26-105">Quantum encoding and processing of information is a powerful alternative to classical machine learning Quantum classifiers.</span></span> <span data-ttu-id="0be26-106">Em particular, permite-nos codificar dados em registos quânticos concisos em relação ao número de funcionalidades, empregando sistematicamente o emaranhamento quântico como recurso computacional e utilizando a medição quântica para a inferência da classe.</span><span class="sxs-lookup"><span data-stu-id="0be26-106">In particular, it allows us to encode data in quantum registers that are concise relative to the number of features, systematically employing quantum entanglement as computational resource and employing quantum measurement for class inference.</span></span>
<span data-ttu-id="0be26-107">O classificador quântico centrado em circuitos é uma solução quântica relativamente simples que combina codificação de dados com um circuito quântico emaranhamento/disentangling rápido seguido de medição para inferir rótulos de classe de amostras de dados.</span><span class="sxs-lookup"><span data-stu-id="0be26-107">Circuit centric quantum classifier is a relatively simple quantum solution that combines data encoding with a rapidly entangling/disentangling quantum circuit followed by measurement to infer class labels of data samples.</span></span>
<span data-ttu-id="0be26-108">O objetivo é garantir a caracterização clássica e armazenamento de circuitos sujeitos, bem como o treino quântico/clássico híbrido dos parâmetros do circuito, mesmo para espaços de características extremamente grandes.</span><span class="sxs-lookup"><span data-stu-id="0be26-108">The goal is to ensure classical characterization and storage of subject circuits, as well as hybrid quantum/classical training of the circuit parameters even for extremely large feature spaces.</span></span>

## <a name="classifier-architecture"></a><span data-ttu-id="0be26-109">Arquitetura de classificador</span><span class="sxs-lookup"><span data-stu-id="0be26-109">Classifier architecture</span></span>

<span data-ttu-id="0be26-110">A classificação é uma tarefa de aprendizagem automática supervisionada, onde o objetivo é inferir etiquetas de classe $ \{ y_1,y_2,\ldots,y_d \} de $100 de certas amostras de dados.</span><span class="sxs-lookup"><span data-stu-id="0be26-110">Classification is a supervised machine learning task, where the goal is to infer class labels $\{y_1,y_2,\ldots,y_d\}$ of certain data samples.</span></span> <span data-ttu-id="0be26-111">O "conjunto de dados de treino" é uma coleção de amostras $\mathcal{D}= \{ (x,y)}} com etiquetas pré-atribuídas conhecidas.</span><span class="sxs-lookup"><span data-stu-id="0be26-111">The "training data set" is a collection of samples $\mathcal{D}=\{(x,y)}$ with known pre-assigned labels.</span></span> <span data-ttu-id="0be26-112">Aqui $x$ é uma amostra de dados e $y$ é a sua conhecida etiqueta chamada "etiqueta de treino".</span><span class="sxs-lookup"><span data-stu-id="0be26-112">Here $x$ is a data sample and $y$ is its known label called "training label".</span></span>
<span data-ttu-id="0be26-113">Um pouco semelhante aos métodos tradicionais, a classificação quântica consiste em três etapas:</span><span class="sxs-lookup"><span data-stu-id="0be26-113">Somewhat similar to traditional methods, quantum classification consists of three steps:</span></span>
- <span data-ttu-id="0be26-114">codificação de dados</span><span class="sxs-lookup"><span data-stu-id="0be26-114">data encoding</span></span>
- <span data-ttu-id="0be26-115">preparação de um estado classificador</span><span class="sxs-lookup"><span data-stu-id="0be26-115">preparation of a classifier state</span></span>
- <span data-ttu-id="0be26-116">medição Devido à natureza probabilística da medição, estes três passos devem ser repetidos várias vezes.</span><span class="sxs-lookup"><span data-stu-id="0be26-116">measurement Due to the probabilistic nature of the measurement, these three steps must be repeated multiple times.</span></span> <span data-ttu-id="0be26-117">Tanto a codificação como a computação do estado classificador são feitas através de *circuitos quânticos.*</span><span class="sxs-lookup"><span data-stu-id="0be26-117">Both the encoding and the computing of the classifier state are done by means of *quantum circuits*.</span></span> <span data-ttu-id="0be26-118">Embora o circuito de codificação seja normalmente orientado por dados e sem parâmetros, o circuito de classificação contém um conjunto suficiente de parâmetros aprecáveis.</span><span class="sxs-lookup"><span data-stu-id="0be26-118">While the encoding circuit is usually data-driven and parameter-free, the classifier circuit contains a sufficient set of learnable parameters.</span></span> 

<span data-ttu-id="0be26-119">Na solução proposta, o circuito classificador é composto por rotações de um único qubit e rotações controladas de dois qubits.</span><span class="sxs-lookup"><span data-stu-id="0be26-119">In the proposed solution the classifier circuit is composed of single-qubit rotations and two-qubit controlled rotations.</span></span> <span data-ttu-id="0be26-120">Os parâmetros apregáveis aqui são os ângulos de rotação.</span><span class="sxs-lookup"><span data-stu-id="0be26-120">The learnable parameters here are the rotation angles.</span></span> <span data-ttu-id="0be26-121">Os portões de rotação e rotação controlados são conhecidos por serem *universais* para a computação quântica, o que significa que qualquer matriz de peso unitário pode ser decomposta num circuito suficientemente longo, composto por tais portões.</span><span class="sxs-lookup"><span data-stu-id="0be26-121">The rotation and controlled rotation gates are known to be *universal* for quantum computation, which means that any unitary weight matrix can be decomposed into a long enough circuit consisting of such gates.</span></span>

<span data-ttu-id="0be26-122">Na versão proposta, apenas é suportado um circuito seguido de uma estimativa de frequência única.</span><span class="sxs-lookup"><span data-stu-id="0be26-122">In the proposed version, only one circuit followed by a single frequency estimation is supported.</span></span>
<span data-ttu-id="0be26-123">Assim, a solução é um analógico quântico de uma máquina vetorial de suporte com um núcleo polinómio de baixo grau.</span><span class="sxs-lookup"><span data-stu-id="0be26-123">Thus, the solution is a quantum analog of a support vector machine with a low-degree polynomial kernel.</span></span>

![Perceptron multicamacro contra o classificador centrado em circuito](~/media/DLvsQCC.png)

<span data-ttu-id="0be26-125">Um design de classificador quântico simples pode ser comparado com uma solução tradicional de vetor de suporte (SVM).</span><span class="sxs-lookup"><span data-stu-id="0be26-125">A simple quantum classifier design can be compared to a traditional support vector machine (SVM) solution.</span></span> <span data-ttu-id="0be26-126">A inferência para uma amostra de dados $x$ no caso de SVM é feita usando um núcleo ideal $\sum \alpha_j k (x_j,x)$ onde $k$ é uma determinada função de kernel.</span><span class="sxs-lookup"><span data-stu-id="0be26-126">The inference for a data sample $x$ in case of SVM is done using an optimal kernel form $\sum \alpha_j  k(x_j,x)$ where $k$ is a certain kernel function.</span></span>

<span data-ttu-id="0be26-127">Em contraste, um classificador quântico usa o preditor $p(y│x,U(\theta))=〈U(\theta)x|M|U(\theta)x〉$, que é semelhante em espírito, mas tecnicamente bastante diferente.</span><span class="sxs-lookup"><span data-stu-id="0be26-127">By contrast, a quantum classifier uses the predictor $p(y│x,U(\theta))=〈U(\theta)x|M|U(\theta)x〉$, which is similar in spirit but technically quite different.</span></span> <span data-ttu-id="0be26-128">Assim, quando é utilizada uma codificação simples de amplitude, $p(y│x,U(\theta)$ é uma forma quadrática nas amplitudes de $x$, mas os coeficientes desta forma já não são aprendidos de forma independente; são, em vez disso, agregados a partir dos elementos matricias do circuito $U(\theta)$, que normalmente tem significativamente menos parâmetros apreitáveis $\theta$ do que a dimensão do vetor $x$.</span><span class="sxs-lookup"><span data-stu-id="0be26-128">Thus, when a straightforward amplitude encoding is used,  $p(y│x,U(\theta))$ is a quadratic form in the amplitudes of $x$, but the coefficients of this form are no longer learned independently; they are instead aggregated from the matrix elements of the circuit $U(\theta)$, which typically has significantly fewer learnable parameters $\theta$ than the dimension of the vector $x$.</span></span> <span data-ttu-id="0be26-129">O grau polinómico de $p(y│x,U(\theta)$ nas características originais pode ser aumentado para $2^l$ usando um produto quântico codificando $l$ cópias de $x$.</span><span class="sxs-lookup"><span data-stu-id="0be26-129">The polynomial degree of $p(y│x,U(\theta))$ in the original features can be increased to $2^l$ by using a quantum product encoding on $l$ copies of $x$.</span></span>

<span data-ttu-id="0be26-130">A nossa arquitetura explora circuitos relativamente rasos, que, portanto, devem ser *rapidamente emaranhados* para capturar todas as correlações entre as características dos dados em todas as gamas.</span><span class="sxs-lookup"><span data-stu-id="0be26-130">Our architecture explores relatively shallow circuits, which therefore must be *rapidly entangling* in order to capture all the correlations between the data features at all ranges.</span></span> <span data-ttu-id="0be26-131">Um exemplo do componente de circuito de enredar rápido mais útil é mostrado na figura abaixo.</span><span class="sxs-lookup"><span data-stu-id="0be26-131">An example of the most useful rapidly entangling circuit component is shown on figure below.</span></span> <span data-ttu-id="0be26-132">Mesmo que um circuito com esta geometria consista em apenas $3 n+1$ portões, a matriz de peso unitário que calcula garante conversas cruzadas significativas entre as características de $2^n$ .</span><span class="sxs-lookup"><span data-stu-id="0be26-132">Even though a circuit with this geometry consists of only $3 n+1$ gates, the unitary weight matrix that it computes ensures significant cross-talk between $2^n$ features.</span></span>

![Circuito quântico em 5 qubits (com duas camadas cíclicas).](~/media/5-qubit-qccc.png)

<span data-ttu-id="0be26-134">O circuito no exemplo acima é composto por 6 portões de um único qubit $(G_1,\ldots,G_5; G_ {16} )$ e 10 portões de dois qubits $(G_6,\ldots,G_ {15} )$.</span><span class="sxs-lookup"><span data-stu-id="0be26-134">The circuit in the above example consists of 6 single-qubit gates $(G_1,\ldots,G_5; G_{16})$ and 10 two-qubits gates $(G_6,\ldots,G_{15})$.</span></span> <span data-ttu-id="0be26-135">Assumindo que cada um dos portões é definido com um parâmetro aprecável temos 16 parâmetros aprecíveis, enquanto a dimensão do espaço Hilbert de 5 qubits é de 32.</span><span class="sxs-lookup"><span data-stu-id="0be26-135">Assuming that each of the gates is defined with one learnable parameter we have 16 learnable parameters, while the dimension of the 5-qubit Hilbert space is 32.</span></span> <span data-ttu-id="0be26-136">Tal geometria de circuito pode ser facilmente generalizada a qualquer registo de $n$-qubit, quando $n$ é estranho, cedendo circuitos com parâmetros de $3 n+1$ para $2^n$-dimensional feature space.</span><span class="sxs-lookup"><span data-stu-id="0be26-136">Such circuit geometry can be easily generalized to any $n$-qubit register, when $n$ is odd, yielding circuits with $3 n+1$ parameters for $2^n$-dimensional feature space.</span></span>

## <a name="classifier-training-as-a-supervised-learning-task"></a><span data-ttu-id="0be26-137">Formação de classificador como tarefa de aprendizagem supervisionada</span><span class="sxs-lookup"><span data-stu-id="0be26-137">Classifier training as a supervised learning task</span></span>

<span data-ttu-id="0be26-138">A formação de um modelo de classificador implica encontrar valores ideais dos seus parâmetros operacionais, de modo a maximizar a probabilidade média de inferir os rótulos de treino corretos através das amostras de treino.</span><span class="sxs-lookup"><span data-stu-id="0be26-138">Training of a classifier model involves finding optimal values of its operational parameters, such that they maximize the average likelihood of inferring the correct training labels across the training samples.</span></span>
<span data-ttu-id="0be26-139">Aqui, preocupamo-nos apenas com a classificação de dois níveis, ou seja, o caso de $d=2$ e apenas duas classes com os rótulos $y_1,y_2$.</span><span class="sxs-lookup"><span data-stu-id="0be26-139">Here, we concern ourselves with two level classification only, i.e. the case of $d=2$ and only two classes with the labels $y_1,y_2$.</span></span>

> [!NOTE]
> <span data-ttu-id="0be26-140">Uma forma de generalizar os nossos métodos para um número arbitrário de classes é substituir qubits por qudits, ou seja, unidades quânticas por estados de base $d$, e a medição bidirecionais com $d medição de $-way.</span><span class="sxs-lookup"><span data-stu-id="0be26-140">A principled way of generalizing our methods to arbitrary number of classes is to replace qubits with qudits, i.e. quantum units with $d$ basis states, and the two-way measurement with $d$-way measurement.</span></span>

### <a name="likelihood-as-the-training-goal"></a><span data-ttu-id="0be26-141">Probabilidade como objetivo de treino</span><span class="sxs-lookup"><span data-stu-id="0be26-141">Likelihood as the training goal</span></span>

<span data-ttu-id="0be26-142">Dado um circuito quântico apresuável $U(\theta)$, onde $\theta$ é um vetor de parâmetros, e denotando a medição final por $M$, a probabilidade média da inferência correta da etiqueta é $$ \start{l}y_1 {1} sum_ | |(mathcal{L}y_1|} U(\theta) x) + \sum_{(x,y_2)\in\mathcal{D}} P(M=y_2| U(\theta) x)\right) \end{align} $$ onde $P(M=y|z)$ é a probabilidade de medir $y$ em estado quântico $z$.</span><span class="sxs-lookup"><span data-stu-id="0be26-142">Given a learnable quantum circuit $U(\theta)$, where $\theta$ is a vector of parameters, and denoting the final measurement by $M$, the average likelihood of the correct label inference is $$ \begin{align} \mathcal{L}(\theta)=\frac{1}{|\mathcal{D}|} \left( \sum_{(x,y_1)\in\mathcal{D}} P(M=y_1|U(\theta) x) + \sum_{(x,y_2)\in\mathcal{D}} P(M=y_2|U(\theta) x)\right) \end{align} $$ where $P(M=y|z)$ is the probability of measuring $y$ in quantum state $z$.</span></span>
<span data-ttu-id="0be26-143">Aqui, basta entender que a função de probabilidade $\mathcal{L}(\theta)$ é suave em $\theta$ e a sua derivada em qualquer $\theta_j$ pode ser calculada essencialmente pelo mesmo protocolo quântico usado para calcular a função de probabilidade em si.</span><span class="sxs-lookup"><span data-stu-id="0be26-143">Here, it suffices to understand that the likelihood function $\mathcal{L}(\theta)$ is smooth in $\theta$ and its derivative in any $\theta_j$ can be computed by essentially the same quantum protocol as used for computing the likelihood function itself.</span></span> <span data-ttu-id="0be26-144">Isto permite otimizar o $\mathcal{L}(\theta)$ por descida de gradiente.</span><span class="sxs-lookup"><span data-stu-id="0be26-144">This allows for optimizing the $\mathcal{L}(\theta)$ by gradient descent.</span></span>

### <a name="classifier-bias-and-training-score"></a><span data-ttu-id="0be26-145">Viés de classificado e pontuação de treino</span><span class="sxs-lookup"><span data-stu-id="0be26-145">Classifier bias and training score</span></span>

<span data-ttu-id="0be26-146">Tendo em conta alguns valores intermédios (ou finais) dos parâmetros em $\theta$, precisamos identificar um único valor real $b$ conhecido como *viés de classificador* para fazer a inferência.</span><span class="sxs-lookup"><span data-stu-id="0be26-146">Given some intermediate (or final) values of the parameters in $\theta$, we need to identify a single real value $b$ know as *classifier bias* to do the inference.</span></span> <span data-ttu-id="0be26-147">A regra da inferência do rótulo funciona da seguinte forma:</span><span class="sxs-lookup"><span data-stu-id="0be26-147">The label inference rule works as follows:</span></span> 
- <span data-ttu-id="0be26-148">Uma amostra $x$ é atribuída $y_2$ se e somente se $P (M=y_2| U(\theta) x) + b > 0,5$ (REGRA1) (caso contrário, é atribuída a etiqueta $y_1$)</span><span class="sxs-lookup"><span data-stu-id="0be26-148">A sample $x$ is assigned label $y_2$ if and only if $P(M=y_2|U(\theta) x) + b > 0.5$  (RULE1) (otherwise it is assigned label $y_1$)</span></span>

<span data-ttu-id="0be26-149">É evidente $b$ deve estar no intervalo $(-0,5,0,5)$ para ser significativo.</span><span class="sxs-lookup"><span data-stu-id="0be26-149">Clearly $b$ must be in the interval $(-0.5,+0.5)$ to be meaningful.</span></span>

<span data-ttu-id="0be26-150">Um caso de treino $(x,y) \in \mathcal{D}$ é considerado uma *classificação errada* dado o preconceito $b$ se o rótulo inferido por $x$ como por RULE1 é realmente diferente de $y$.</span><span class="sxs-lookup"><span data-stu-id="0be26-150">A training case $(x,y) \in \mathcal{D}$ is considered a *misclassification* given the bias $b$ if the label inferred for $x$ as per RULE1 is actually different from $y$.</span></span> <span data-ttu-id="0be26-151">O número total de classificações erradas é a *pontuação* de treino do classificador dado o preconceito $b$.</span><span class="sxs-lookup"><span data-stu-id="0be26-151">The overall number of misclassifications is the *training score* of the classifier given the bias $b$.</span></span> <span data-ttu-id="0be26-152">O *viés de* classificador ideal $b$ minimiza a pontuação do treino.</span><span class="sxs-lookup"><span data-stu-id="0be26-152">The *optimal* classifier bias $b$ minimizes the training score.</span></span> <span data-ttu-id="0be26-153">É fácil ver que, dadas as estimativas de probabilidade pré-computação $ \{ P(M=y_2| U(\theta) x) | (x,\*)\in\mathcal{D} \} $, o viés de classificação ideal pode ser encontrado através de uma pesquisa binária no intervalo $(-0,5,0,5)$ fazendo no máximo $\log_2(|\mathcal{D}|) Passos de $000.</span><span class="sxs-lookup"><span data-stu-id="0be26-153">It is easy to see that, given the precomputed probability estimates $\{ P(M=y_2|U(\theta) x) | (x,\*)\in\mathcal{D} \}$, the optimal classifier bias can be found by binary search in interval $(-0.5,+0.5)$ by making at most $\log_2(|\mathcal{D}|)$ steps.</span></span>

### <a name="reference"></a><span data-ttu-id="0be26-154">Referência</span><span class="sxs-lookup"><span data-stu-id="0be26-154">Reference</span></span>

<span data-ttu-id="0be26-155">Esta informação deve ser suficiente para começar a brincar com o código.</span><span class="sxs-lookup"><span data-stu-id="0be26-155">This information should be enough to start playing with the code.</span></span> <span data-ttu-id="0be26-156">No entanto, se quiser saber mais sobre este modelo, leia a proposta original: [ *"Classificadores quânticos centrados em circuitos", Maria Schuld, Alex Bocharov, Krysta Svore e Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span><span class="sxs-lookup"><span data-stu-id="0be26-156">However, if you want to learn more about this model, please read the original proposal: [*'Circuit-centric quantum classifiers', Maria Schuld, Alex Bocharov, Krysta Svore and Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span></span>

<span data-ttu-id="0be26-157">Além da amostra de código que você verá nos próximos passos, você também pode começar a explorar a classificação quântica [neste tutorial](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification)</span><span class="sxs-lookup"><span data-stu-id="0be26-157">In addition to the code sample you will see in the next steps, you can also start exploring quantum classification in [this tutorial](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification)</span></span> 
